name: Generate Sitemap

env:
  TZ: Asia/Tokyo

on:
  push:

jobs:
  get_articles:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      articles: ${{ steps.sorted_articles.outputs.result }}
    steps:
      - uses: actions/github-script@v7
        id: sorted_articles
        with:
          result-encoding: json
          script: |
            const exampleUrl = "https://example.com";
            const perPage = 3;
            let maxPage = 1;
            let result = [];
            for (let page = 1; page <= maxPage; page += 1) {
              const res = await fetch(`https://render-sample-1.onrender.com/articles?page=${page}&per_page=${perPage}`, {
                headers: {
                  "Content-Type": "application/json",
                  "x-api-key": "${{ secrets.X_API_KEY }}"
                }
              });
              if (!res.ok) {
                throw new Error(res.text)
              }
              const resJson = await res.json();
              result = resJson.articles.reduce((acc, cur) => {
                return [
                  ...acc,
                  {
                    url: `${exampleUrl}/${cur.route}/${cur.slug}/`,
                    refreshed_at: cur.refreshed_at
                  }
                ]
              }, result);
              maxPage = (resJson.total + perPage - 1) / perPage;
            }
            result.sort((a, b) => {
              return new Date(b.refreshed_at) - new Date(a.refreshed_at);
            })
            return result;
  get_users:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    outputs:
      users: ${{ steps.sorted_users.outputs.result }}
    steps:
      - uses: actions/github-script@v7
        id: sorted_users
        with:
          result-encoding: json
          script: |
            const exampleUrl = "https://example.com";
            const perPage = 3;
            let maxPage = 1;
            let result = [];
            for (let page = 1; page <= maxPage; page += 1) {
              const res = await fetch(`https://render-sample-1.onrender.com/users?page=${page}&per_page=${perPage}`, {
                headers: {
                  "Content-Type": "application/json",
                  "x-api-key": "${{ secrets.X_API_KEY }}"
                }
              });
              if (!res.ok) {
                throw new Error(res.text)
              }
              const resJson = await res.json();
              result = resJson.users.reduce((acc, cur) => {
                return [
                  ...acc,
                  {
                    url: `${exampleUrl}/${cur.id}/`,
                    refreshed_at: cur.refreshed_at
                  }
                ]
              }, result);
              maxPage = (resJson.total + perPage - 1) / perPage;
            }
            result.sort((a, b) => {
              return new Date(b.refreshed_at) - new Date(a.refreshed_at);
            })
            return result;
  extract_exists_urls:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs:
      - get_articles
      - get_users
    outputs:
      urls: ${{ steps.exists_urls.outputs.result }}
    steps:
      - uses: actions/github-script@v7
        id: exists_urls
        with:
          result-encoding: json
          script: |
            const articles = ${{ needs.get_articles.outputs.articles }}.map((article) => article.url);
            const users = ${{ needs.get_users.outputs.users }}.map((user) => user.url);
            const defaults = [
              "https://example.com/news/",
              "https://example.com/",
              "https://example.com/news/about/"
            ];

            const targetUrls = [...articles, ...users, ...defaults];
            const result = [];

            for (const url of targetUrls) {
              result.push(url);
            }

            console.log(result);
            return result;
  generate_sitemap:
    runs-on: ubuntu-latest
    timeout-minutes: 10
    needs:
      - extract_exists_urls
    steps:
      - uses: actions/checkout@v4
      - run: |
          urls=${{ needs.extract_exists_urls.outputs.urls }}
          urls=${{ fromJSON(${urls}) }}
          str="<?xml version="1.0" encoding="UTF-8"?>\n<urlset xmlns="http://www.sitemaps.org/schemas/sitemap/0.9">\n"
          for url in urls; do
            str+="  <url>\n    <loc>${url}</loc>\n  </url>\n"
          done
          str+="</urlset>"
          echo -e ${str} > apps/web/public/sitemap.xml
          cat apps/web/public/sitemap.xml
